{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for LLM-Redial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import config\n",
    "import nltk\n",
    "import json\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scripts.data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "We import the tokenizer, common stopwords, lemmatization (wordnet) and part-of-speech tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nicolasespinoza/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nicolasespinoza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nicolasespinoza/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nicolasespinoza/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "We used the DataLoader class to load the data. Returns a dict for each type of dataset tat we have on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for Movies...\n",
      "Data for Movies loaded successfully.\n",
      "\n",
      "Loading data for Books...\n",
      "Data for Books loaded successfully.\n",
      "\n",
      "Loading data for Electronics...\n",
      "Data for Electronics loaded successfully.\n",
      "\n",
      "Loading data for Sports...\n",
      "Data for Sports loaded successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "dataframes = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Movies', 'Books', 'Electronics', 'Sports'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the loaded dataframes, we need to access to the category of the data and then check the different dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['item_map', 'user_map', 'final_data', 'dialogues'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['Movies'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can access to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>history_interaction</th><th>user_might_like</th><th>conversations</th></tr><tr><td>str</td><td>list[str]</td><td>list[str]</td><td>struct[15]</td></tr></thead><tbody><tr><td>&quot;A275WB4PYH6227&quot;</td><td>[&quot;0782008372&quot;, &quot;6304109318&quot;, … &quot;B000654YIS&quot;]</td><td>[&quot;B000N3AW6G&quot;]</td><td>{{540,[&quot;6303855482&quot;],[&quot;B00003CXN4&quot;],[&quot;B000N3AW6G&quot;]},null,null,null,null,null,null,null,null,null,null,null,null,null,null}</td></tr><tr><td>&quot;A2T6T8JBP9DVCG&quot;</td><td>[&quot;6300214621&quot;, &quot;079072961X&quot;, … &quot;6300214052&quot;]</td><td>[&quot;B00EXPOCXY&quot;, &quot;0783245130&quot;, … &quot;B001PR0Y4O&quot;]</td><td>{{8255,[&quot;6300216179&quot;, &quot;0792836529&quot;, &quot;6304005490&quot;],[],[&quot;B00EXPOCXY&quot;]},{8256,[&quot;6300185370&quot;, &quot;6300158349&quot;, &quot;6304239149&quot;],[],[&quot;0783245130&quot;]},{8257,[&quot;6304005490&quot;, &quot;6301706811&quot;, &quot;6301964314&quot;],[],[&quot;6302101743&quot;]},{8258,[&quot;6302098424&quot;, &quot;B005BYBZKY&quot;],[],[&quot;6302462762&quot;]},{8259,[&quot;6304005490&quot;, &quot;B000GAKBLW&quot;],[],[&quot;6304508441&quot;]},{8260,[&quot;6301106482&quot;, &quot;079072961X&quot;],[],[&quot;B001PR0Y4O&quot;]},null,null,null,null,null,null,null,null,null}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌────────────────┬─────────────────────┬──────────────────┬─────────────────────────────────┐\n",
       "│ user_id        ┆ history_interaction ┆ user_might_like  ┆ conversations                   │\n",
       "│ ---            ┆ ---                 ┆ ---              ┆ ---                             │\n",
       "│ str            ┆ list[str]           ┆ list[str]        ┆ struct[15]                      │\n",
       "╞════════════════╪═════════════════════╪══════════════════╪═════════════════════════════════╡\n",
       "│ A275WB4PYH6227 ┆ [\"0782008372\",      ┆ [\"B000N3AW6G\"]   ┆ {{540,[\"6303855482\"],[\"B00003C… │\n",
       "│                ┆ \"6304109318\", ……    ┆                  ┆                                 │\n",
       "│ A2T6T8JBP9DVCG ┆ [\"6300214621\",      ┆ [\"B00EXPOCXY\",   ┆ {{8255,[\"6300216179\", \"0792836… │\n",
       "│                ┆ \"079072961X\", ……    ┆ \"0783245130\", …… ┆                                 │\n",
       "└────────────────┴─────────────────────┴──────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['Movies']['final_data'].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we check that the \"conversation\" field of the dataframe is a dictionary containing all the necessary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A2NBOL825B93OM'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['Movies']['final_data'].item(1, \"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_1': {'conversation_id': 2,\n",
       "  'user_likes': ['B00003CWT6'],\n",
       "  'user_dislikes': ['B00003CXTL'],\n",
       "  'rec_item': ['B00Z9YZRVE']},\n",
       " 'conversation_2': {'conversation_id': 3,\n",
       "  'user_likes': ['B0009WK5CW', 'B00008W64E'],\n",
       "  'user_dislikes': ['6303575617'],\n",
       "  'rec_item': ['B0001K2L4W']},\n",
       " 'conversation_3': {'conversation_id': 4,\n",
       "  'user_likes': ['B00005JKN2'],\n",
       "  'user_dislikes': ['B00003CXTL', '6303575617', 'B00008MTXY'],\n",
       "  'rec_item': ['B00005JN2Z']},\n",
       " 'conversation_4': None,\n",
       " 'conversation_5': None,\n",
       " 'conversation_6': None,\n",
       " 'conversation_7': None,\n",
       " 'conversation_8': None,\n",
       " 'conversation_9': None,\n",
       " 'conversation_10': None,\n",
       " 'conversation_11': None,\n",
       " 'conversation_12': None,\n",
       " 'conversation_13': None,\n",
       " 'conversation_14': None,\n",
       " 'conversation_15': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['Movies']['final_data'].item(1, \"conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
