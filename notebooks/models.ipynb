{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, BaseMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from scripts.Tools import read_dialogue, get_conversation_by_id "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Books\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/{dataset}/item_map.json\", \"r\") as f:\n",
    "    item_map = json.load(f)\n",
    "\n",
    "with open(f\"../data/{dataset}/final_data.jsonl\", \"r\") as f:\n",
    "    final_data = [json.loads(line) for line in f]\n",
    "\n",
    "dialogues = read_dialogue(f\"../data/{dataset}/Conversation.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(set([item_map[key].lower().strip() for key in item_map]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_interactions = {}\n",
    "for user_data in final_data:\n",
    "    for user_id in user_data:\n",
    "        for item_id in user_data[user_id][\"history_interaction\"]:\n",
    "            item_name = item_map[item_id].lower().strip()\n",
    "            if item_name not in item_interactions:\n",
    "                item_interactions[item_name] = 0\n",
    "            item_interactions[item_name] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages(conversation_id: int, dialogues: str) -> List[BaseMessage]:\n",
    "\n",
    "    conversation = get_conversation_by_id(dialogues, conversation_id)\n",
    "    lines = conversation.strip().split(\"\\n\\n\")\n",
    "    messages = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"User:\"):\n",
    "            messages.append(HumanMessage(content=line[5:].strip()))\n",
    "        elif line.startswith(\"Agent:\"):\n",
    "            messages.append(AIMessage(content=line[6:].strip()))\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models 1\n",
    "\n",
    "In the following subsection, we implement three baseline models for conversational recommendation:\n",
    "\n",
    "1. Random recommendation\n",
    "2. Most popular recommendation\n",
    "3. Zero-shot recommendation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_random(items: List[str], n: int = 5):\n",
    "    return np.random.choice(items, n, replace=False).tolist()\n",
    "\n",
    "\n",
    "def recommend_most_popular(item_interactions: Dict[str, int], n: int = 5):\n",
    "    most_popular_items = sorted(\n",
    "        item_interactions, key=item_interactions.get, reverse=True\n",
    "    )[:n]\n",
    "    return most_popular_items\n",
    "\n",
    "\n",
    "def recommend_zero_shot(messages: List[BaseMessage], n: int = 5, verbose: bool = False):\n",
    "\n",
    "    class Recommendation(BaseModel):\n",
    "        items: Any = Field(\n",
    "            description=\"A list of items. Each item must contain a 'reason' and a 'name'\"\n",
    "        )\n",
    "\n",
    "    system = \"\"\"\n",
    "        You are a recommender system.\n",
    "        Recommend {n} items based on the user's conversation.\n",
    "        Sort the items by descending order of relevance.\n",
    "\n",
    "        Conversation:\n",
    "        {messages}\n",
    "        \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", system)])\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    structured_llm = llm.with_structured_output(Recommendation, include_raw=True)\n",
    "\n",
    "    zero_shot_structured_llm = prompt | structured_llm\n",
    "    response = zero_shot_structured_llm.invoke({\"messages\": messages, \"n\": n})\n",
    "\n",
    "    prompt_tokens = response[\"raw\"].response_metadata[\"token_usage\"][\"prompt_tokens\"]\n",
    "    completion_tokens = response[\"raw\"].response_metadata[\"token_usage\"][\n",
    "        \"completion_tokens\"\n",
    "    ]\n",
    "\n",
    "    cost = 0.150 * prompt_tokens / 1000000 + 0.600 * completion_tokens / 1000000\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "        print(f\"Completion Tokens: {completion_tokens}\")\n",
    "        print(f\"Cost: ${cost} USD\")\n",
    "\n",
    "    return response[\"parsed\"].items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['justice for laine (badge of honor: texas heroes) (volume 4)',\n",
       " 'nirv holy bible: the best translation for understanding gods word',\n",
       " 'the edible woman',\n",
       " 'forty signs of rain (science in the capital)',\n",
       " \"flippin' the hustle (wahida clark presents)\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_random(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gone girl',\n",
       " 'the girl on the train',\n",
       " 'the pillars of the earth',\n",
       " 'the old man and the sea',\n",
       " 'books\" />']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_most_popular(item_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '\"The Perfect Couple\"',\n",
       "  'reason': \"This book features a gripping drama with complex relationships and unexpected twists, similar to the engaging storytelling in 'We Both Can't Be Bae (Volume 1)'.\"},\n",
       " {'name': '\"The Seven Husbands of Evelyn Hugo\"',\n",
       "  'reason': 'A captivating tale of love, betrayal, and the glamorous yet tumultuous life of a Hollywood icon, which will keep you hooked just like your previous read.'},\n",
       " {'name': '\"The Nightingale\"',\n",
       "  'reason': 'This historical fiction novel is rich in drama and emotional depth, focusing on the lives of two sisters during World War II, making it a compelling read for fans of intense narratives.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = get_messages(0, dialogues)\n",
    "recommend_zero_shot(messages[:1], n=3, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models 2\n",
    "\n",
    "In the following subsection, we implement the first agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important tool is the vector database, as it allows to interact semantically with the currrent catalog of books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from uuid import uuid4\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_count(text: str) -> int:\n",
    "    model = \"text-embedding-3-small\"\n",
    "    encoding_name = tiktoken.encoding_for_model(model).name\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    total_tokens = len(encoding.encode(text))\n",
    "\n",
    "    return total_tokens\n",
    "\n",
    "def get_embedding_cost(num_tokens: int) -> float:\n",
    "    cost_per_million_tokens = 0.020\n",
    "    return cost_per_million_tokens * (num_tokens / 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for item in items:\n",
    "    if item != \"\":\n",
    "        documents.append(Document(page_content=f\"Book: {item}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168823"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 2150836\n",
      "Expected cost: 0.04301671999999588\n"
     ]
    }
   ],
   "source": [
    "total_tokens = 0\n",
    "expected_cost = 0\n",
    "for doc in documents:\n",
    "    tokens = get_token_count(doc.page_content)\n",
    "    total_tokens += tokens\n",
    "    expected_cost += get_embedding_cost(tokens)\n",
    "print(f\"Total tokens: {total_tokens}\")\n",
    "print(f\"Expected cost: {expected_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "store = Chroma(\n",
    "    collection_name=\"books\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"../store\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uuids = [str(uuid4()) for _ in documents]\n",
    "# Iterate in batches of 10,000\n",
    "#for i in range(0, len(documents), 10_000):\n",
    "#    print(f\"Adding documents {i} to {i + 10_000}\")\n",
    "#    store.add_documents(documents=documents[i : i + 10_000], ids=uuids[i : i + 10_000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.tools import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool = TavilySearchResults(\n",
    "    max_results=3,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=False,\n",
    "    include_raw_content=False,\n",
    "    include_images=False,\n",
    "    description=\"Search the web for information about books.\",\n",
    "    )\n",
    "\n",
    "books_retriever = create_retriever_tool(\n",
    "    store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}),\n",
    "    \"retrieve_books\",\n",
    "    \"Search and return books in the database.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    recommendations: Optional[Sequence[str]] = None\n",
    "\n",
    "\n",
    "async def agent(state):\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        template=\"\"\"\n",
    "            You are a conversational recommender system specialized in books.\n",
    "            Given a current conversation, recommend 3 books that align with the user's interests.\n",
    "\n",
    "            Current conversation is as follows:\n",
    "            {messages}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        streaming=True,\n",
    "        model=\"gpt-4o-mini\",\n",
    "        model_kwargs={\"stream_options\": {\"include_usage\": True}},\n",
    "    )\n",
    "\n",
    "    tools = [books_retriever, tavily_tool]\n",
    "\n",
    "    llm = llm.bind_tools(tools)\n",
    "\n",
    "    chain = prompt | llm\n",
    "\n",
    "    response = await chain.ainvoke({\"messages\": messages})\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def should_continue(state):\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if not last_message.tool_calls:\n",
    "        return END\n",
    "    else:\n",
    "        return \"tools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "tools = ToolNode([books_retriever, tavily_tool])\n",
    "\n",
    "workflow.add_node(\"agent\", RunnableLambda(agent))\n",
    "workflow.add_node(\"tools\", tools)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, {END: END, \"tools\": \"tools\"})\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "workflow.add_edge(\"agent\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = get_messages(0, dialogues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = await graph.ainvoke({\"messages\": messages[0:1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hello! I recently read \"We Both Can\\'t Be Bae (Volume 1)\" and I really enjoyed it. The drama in the story kept me hooked. Can you recommend another book similar to it?', additional_kwargs={}, response_metadata={}, id='ab245e5e-b480-4df9-b848-9e4ec39409fb'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Degr7uzx7HiTDYubrdfZoIkX', 'function': {'arguments': '{\"query\":\"We Both Can\\'t Be Bae (Volume 1)\"}', 'name': 'retrieve_books'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1'}, id='run-56ebe55a-a501-4a9b-a8e1-2f76fa4502e4-0', tool_calls=[{'name': 'retrieve_books', 'args': {'query': \"We Both Can't Be Bae (Volume 1)\"}, 'id': 'call_Degr7uzx7HiTDYubrdfZoIkX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 203, 'output_tokens': 24, 'total_tokens': 227, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"Book: we both can't be bae (volume 1)\\n\\nBook: we both can't be bae 2 (volume 2)\\n\\nBook: you &amp; me (volume 1)\", name='retrieve_books', id='9c177d4e-27d4-4739-b907-94e7b8ef1c14', tool_call_id='call_Degr7uzx7HiTDYubrdfZoIkX'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_GhHWYTAwWP8ierxemeixIGBm', 'function': {'arguments': '{\"query\": \"we both can\\'t be bae 2 (volume 2)\"}', 'name': 'retrieve_books'}, 'type': 'function'}, {'index': 1, 'id': 'call_wuZNaSjEXnzsiN3G6hSYtUej', 'function': {'arguments': '{\"query\": \"you & me (volume 1)\"}', 'name': 'retrieve_books'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1'}, id='run-36ec8b6c-e90d-4317-8752-7792d0f2d664-0', tool_calls=[{'name': 'retrieve_books', 'args': {'query': \"we both can't be bae 2 (volume 2)\"}, 'id': 'call_GhHWYTAwWP8ierxemeixIGBm', 'type': 'tool_call'}, {'name': 'retrieve_books', 'args': {'query': 'you & me (volume 1)'}, 'id': 'call_wuZNaSjEXnzsiN3G6hSYtUej', 'type': 'tool_call'}], usage_metadata={'input_tokens': 569, 'output_tokens': 62, 'total_tokens': 631, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"Book: we both can't be bae 2 (volume 2)\\n\\nBook: we both can't be bae (volume 1)\\n\\nBook: two can play (alphachat.com) (volume 2)\", name='retrieve_books', id='ab2d9a69-00d3-4305-9b24-f9cbbffcab76', tool_call_id='call_GhHWYTAwWP8ierxemeixIGBm'),\n",
       "  ToolMessage(content='Book: you &amp; me (volume 1)\\n\\nBook: love me ~ like that (volume 1)\\n\\nBook: just us (just series) (volume 1)', name='retrieve_books', id='d53b085f-108a-498e-863c-91e1fd9554c5', tool_call_id='call_wuZNaSjEXnzsiN3G6hSYtUej'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_U9PakbzshqhTLmukevckm7cH', 'function': {'arguments': '{\"query\": \"love me ~ like that (volume 1)\"}', 'name': 'retrieve_books'}, 'type': 'function'}, {'index': 1, 'id': 'call_eW7oSGzTXhcAsElSlwXpT0s3', 'function': {'arguments': '{\"query\": \"just us (just series) (volume 1)\"}', 'name': 'retrieve_books'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1'}, id='run-7656e111-1736-4106-a0b3-6bb663c86171-0', tool_calls=[{'name': 'retrieve_books', 'args': {'query': 'love me ~ like that (volume 1)'}, 'id': 'call_U9PakbzshqhTLmukevckm7cH', 'type': 'tool_call'}, {'name': 'retrieve_books', 'args': {'query': 'just us (just series) (volume 1)'}, 'id': 'call_eW7oSGzTXhcAsElSlwXpT0s3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1154, 'output_tokens': 63, 'total_tokens': 1217, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Book: love me ~ like that (volume 1)\\n\\nBook: give me love (give me series) (volume 1)\\n\\nBook: love me', name='retrieve_books', id='bccdc125-661b-43e6-8c71-4b3855cf6d7f', tool_call_id='call_U9PakbzshqhTLmukevckm7cH'),\n",
       "  ToolMessage(content='Book: just us (just series) (volume 1)\\n\\nBook: one just man (volume 1)\\n\\nBook: us (him) (volume 2)', name='retrieve_books', id='3335f51a-4c15-4127-9280-40df77a53648', tool_call_id='call_eW7oSGzTXhcAsElSlwXpT0s3'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_vDKtjmrhtv6HNarB1JB058vR', 'function': {'arguments': '{\"query\": \"give me love (give me series) (volume 1)\"}', 'name': 'retrieve_books'}, 'type': 'function'}, {'index': 1, 'id': 'call_LlCReJAcjsBtjIi5Yvefmq4B', 'function': {'arguments': '{\"query\": \"one just man (volume 1)\"}', 'name': 'retrieve_books'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1'}, id='run-12e79f73-c6ab-477c-b935-b776e13b0ac7-0', tool_calls=[{'name': 'retrieve_books', 'args': {'query': 'give me love (give me series) (volume 1)'}, 'id': 'call_vDKtjmrhtv6HNarB1JB058vR', 'type': 'tool_call'}, {'name': 'retrieve_books', 'args': {'query': 'one just man (volume 1)'}, 'id': 'call_LlCReJAcjsBtjIi5Yvefmq4B', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1728, 'output_tokens': 63, 'total_tokens': 1791, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Book: give me love (give me series) (volume 1)\\n\\nBook: love me ~ like that (volume 1)\\n\\nBook: sweet love (the sweet series) (volume 1)', name='retrieve_books', id='b0bdeb68-9843-446d-a938-ac84b18bf5fc', tool_call_id='call_vDKtjmrhtv6HNarB1JB058vR'),\n",
       "  ToolMessage(content=\"Book: one just man (volume 1)\\n\\nBook: that man 1 (that man trilogy) (volume 1)\\n\\nBook: one man's island (volume 1)\", name='retrieve_books', id='aa16046b-8ae5-4a34-86ea-d5707614936e', tool_call_id='call_LlCReJAcjsBtjIi5Yvefmq4B'),\n",
       "  AIMessage(content='Based on your interest in \"We Both Can\\'t Be Bae (Volume 1)\" and the drama that kept you hooked, here are three book recommendations that you might enjoy:\\n\\n1. **We Both Can\\'t Be Bae (Volume 2)** - Continuing the story from the first volume, this sequel promises more drama and engaging plot twists.\\n\\n2. **Love Me ~ Like That (Volume 1)** - This book features a compelling romantic storyline with emotional depth, perfect for fans of dramatic narratives.\\n\\n3. **Just Us (Just Series) (Volume 1)** - A story that explores relationships and the complexities of love, filled with drama and heartfelt moments.\\n\\nThese selections should resonate well with your taste! Happy reading!', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1'}, id='run-53bf8ede-e02e-43b9-935f-62fc366474cc-0', usage_metadata={'input_tokens': 2308, 'output_tokens': 146, 'total_tokens': 2454, 'input_token_details': {'audio': 0, 'cache_read': 1664}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_cost(messages: list[BaseMessage]) -> float:\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "\n",
    "    for message in messages:\n",
    "        if isinstance(message, AIMessage):\n",
    "            input_tokens += message.usage_metadata[\"input_tokens\"]\n",
    "            output_tokens += message.usage_metadata[\"output_tokens\"]\n",
    "    return input_tokens * 0.150 / 1_000_000 + output_tokens * 0.0600 / 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00091578"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_inference_cost(output[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
